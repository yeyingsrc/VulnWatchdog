#!/usr/bin/env python3
"""
é‡ç»„ç›®å½•ç»“æ„ï¼šæŒ‰å‘ç°æ—¶é—´ï¼ˆcreated_atï¼‰åˆ†ç±»åˆ° YYYY/MM/ ç›®å½•
"""

import os
import shutil
import sqlite3
from pathlib import Path
from datetime import datetime
from collections import defaultdict
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

def reorganize_reports():
    """é‡ç»„æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶"""

    logger.info("ğŸš€ å¼€å§‹é‡ç»„ç›®å½•ç»“æ„...\n")

    # è¿æ¥æ•°æ®åº“
    db = sqlite3.connect('vulns.db')
    cursor = db.cursor()

    # æŸ¥è¯¢æ‰€æœ‰ä»“åº“åŠå…¶åˆ›å»ºæ—¶é—´
    cursor.execute("""
        SELECT
            cve_id,
            name,
            url,
            created_at,
            gpt_analysis
        FROM repositories
        WHERE gpt_analysis IS NOT NULL
        ORDER BY created_at DESC
    """)

    stats = defaultdict(int)
    moved_count = 0
    skipped_count = 0

    for row in cursor.fetchall():
        cve_id, repo_name, repo_url, created_at, gpt_analysis = row

        # è§£ææ—¶é—´
        try:
            created_date = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
        except Exception as e:
            logger.warning(f"âš ï¸  æ—¶é—´æ ¼å¼å¼‚å¸¸: {cve_id}, è·³è¿‡ ({e})")
            skipped_count += 1
            continue

        # ç›®æ ‡ç›®å½•: data/YYYY/MM/
        year = created_date.strftime('%Y')
        month = created_date.strftime('%m')
        target_dir = Path(f'data/{year}/{month}')
        target_dir.mkdir(parents=True, exist_ok=True)

        # åŸæ–‡ä»¶åï¼ˆä»repo_urlæå–ï¼‰
        repo_full_name = repo_url.replace('https://github.com/', '').replace('/', '_')
        old_filename = f"data/markdown/{cve_id}-{repo_full_name}.md"
        new_filename = target_dir / f"{cve_id}-{repo_full_name}.md"

        # ç§»åŠ¨æ–‡ä»¶
        if os.path.exists(old_filename):
            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡
            if new_filename.exists():
                logger.debug(f"â­ï¸  å·²å­˜åœ¨: {new_filename}")
                stats[f"{year}/{month}"] += 1
                skipped_count += 1
                continue

            shutil.move(old_filename, new_filename)
            moved_count += 1
            stats[f"{year}/{month}"] += 1
            logger.info(f"âœ“ ç§»åŠ¨: {cve_id} -> {year}/{month}/")
        else:
            logger.debug(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {old_filename}")
            skipped_count += 1

    logger.info(f"\nâœ… æ–‡ä»¶ç§»åŠ¨å®Œæˆ!")
    logger.info(f"   æ–°ç§»åŠ¨: {moved_count} ä¸ª")
    logger.info(f"   è·³è¿‡: {skipped_count} ä¸ª")
    logger.info(f"\nğŸ“Š åˆ†å¸ƒç»Ÿè®¡:")
    for period, count in sorted(stats.items(), reverse=True)[:10]:
        logger.info(f"   {period}: {count} ä¸ªæ¼æ´")

    db.close()

    return stats

def create_cve_index():
    """åˆ›å»ºCVEç¼–å·åå‘ç´¢å¼•ï¼ˆç¬¦å·é“¾æ¥ï¼‰"""

    logger.info("\nğŸ”— åˆ›å»ºCVEç´¢å¼•...")

    index_dir = Path('data/by-cve')
    index_dir.mkdir(exist_ok=True)

    created_count = 0

    # éå†æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
    for md_file in Path('data').rglob('*.md'):
        if 'by-cve' in str(md_file) or md_file.name == 'README.md':
            continue

        # æå–CVEç¼–å·
        filename = md_file.name
        if filename.startswith('CVE-'):
            parts = filename.split('-')
            if len(parts) >= 3:
                cve_id = f"{parts[0]}-{parts[1]}-{parts[2]}"

                link_path = index_dir / f"{cve_id}.md"
                relative_target = os.path.relpath(md_file, index_dir)

                # å¦‚æœå·²å­˜åœ¨ï¼Œåˆ é™¤æ—§é“¾æ¥
                if link_path.exists() or link_path.is_symlink():
                    link_path.unlink()

                try:
                    os.symlink(relative_target, link_path)
                    created_count += 1
                except Exception as e:
                    logger.warning(f"âš ï¸  åˆ›å»ºç¬¦å·é“¾æ¥å¤±è´¥: {cve_id} ({e})")

    logger.info(f"âœ“ åˆ›å»ºç´¢å¼•: {created_count} ä¸ªCVE")

if __name__ == '__main__':
    stats = reorganize_reports()
    create_cve_index()
    logger.info("\nâœ… é‡ç»„å®Œæˆ!")
